# ðŸ§  Whisper RAG Assistant

A local Retrieval-Augmented Generation (RAG) assistant that reads and answers questions about your documents using natural language. This project combines **LangChain**, **FAISS**, and **Ollama** running the `qwen:0.6b` model to generate context-aware responses based on your local files.

---

## ðŸ“š Features

- ðŸ“„ Load and process local documents (PDF, TXT, DOCX)
- ðŸ§  Embed content using HuggingFace transformers
- ðŸ—‚ï¸ Index and search vectors with FAISS
- ðŸ¤– Answer natural language questions using `qwen:0.6b` via Ollama
- ðŸ› ï¸ Modular tool integration with LangChain's agent system

---

## âš™ï¸ Technologies Used

- [Python 3.10+](https://www.python.org)
- [LangChain](https://github.com/langchain-ai/langchain)
- [FAISS](https://github.com/facebookresearch/faiss)
- [Ollama](https://ollama.com) â€” running `qwen:0.6b`
- [HuggingFace Embeddings](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)

---

## ðŸš€ Getting Started

### 1. Install Ollama

Download and install [Ollama](https://ollama.com/download) for your platform.

Then pull the model:

```bash
ollama pull qwen:0.6b
```

### 2. Clone the Repository
git clone https://github.com/MarcosHGF/Agentic.git
cd Agentic

### 3. Install Python Dependencies
```bash
pip install -r requirements.txt
```

### 4. Add Your Documents
Place your .pdf, .txt, or .docx files inside the docs/ folder.

Example:
```bash
whisper-rag-assistant/
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ my_notes.pdf
â”‚   â””â”€â”€ project_spec.txt
```

### 5. Run ollama and the Assistant
```bash
ollama run qwen:0.6b
python main.py
```

The system will:
-Check for an existing FAISS index
-If not found, index all documents
-Use qwen:0.6b via Ollama to respond to your queries

### Example Usage
```bash
> What is the main objective of the project?

âœ… FAISS index found. Loading...

Answer:
The project aims to create an AI-powered chatbot that helps users choose items based on preferences, occasion, and mood. It combines computer vision with natural language processing for personalized recommendations.
```
### Project Structure
```bash
Agentic/
â”œâ”€â”€ main.py                # Entry point script
â”œâ”€â”€ doc_indexer.py         # Handles loading, splitting, and indexing documents
â”œâ”€â”€ tools/                 # LangChain tools (e.g., RAG tool)
â”‚   â”œâ”€â”€ tools.py           
â”‚   â””â”€â”€mathtools.py
â”œâ”€â”€ docs/                  # Directory to store documents
â”œâ”€â”€ faiss_index/           # FAISS index directory (auto-generated)
â”œâ”€â”€ requirements.txt       # Python dependencies
â””â”€â”€ README.md              # Project documentation
```

### Model Used
```bash
The assistant runs entirely locally using the Qwen 0.6b language model via Ollama. This ensures:

-Privacy â€” your documents never leave your machine
-Speed â€” no external API calls
-Flexibility â€” use your own tools, data and logic
```